{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "K9n3NzIJWHC2"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load pre-trained model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Sample texts\n",
        "texts = [\"What is a vector database?\", \"How do embeddings work?\", \"AI and ML applications\"]\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = model.encode(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UscSsgWWjZ-",
        "outputId": "8875f3d2-9290-4e82-d321-1501ea1f7419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.02323129 -0.03152992 -0.11742654 ...  0.00061008  0.03184174\n",
            "  -0.05963086]\n",
            " [ 0.01472877 -0.08033437 -0.00036405 ...  0.04816851  0.07535779\n",
            "  -0.02965575]\n",
            " [-0.04623601 -0.07980984  0.02070424 ...  0.0248969  -0.03231503\n",
            "  -0.07868269]]\n"
          ]
        }
      ],
      "source": [
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oI7QuV9cWlcr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "YWzisTxYW3NL"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "# Initialize ChromaDB client\n",
        "client = chromadb.PersistentClient(path=\"./chroma_data\")\n",
        "\n",
        "# Create a collection\n",
        "collection = client.create_collection(name=\"text_search_ex\")\n",
        "\n",
        "# Add embeddings to the collection\n",
        "collection.add(\n",
        "    documents=texts,\n",
        "    metadatas=[{\"source\": \"doc1\"}, {\"source\": \"doc2\"}, {\"source\": \"doc3\"}],\n",
        "    ids=[\"1\", \"2\", \"3\"],\n",
        "    embeddings=embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy-Sb17dXBpp",
        "outputId": "6cae252a-c88d-4472-d4f6-0fb59dcfcff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results: {'ids': [['1', '2']], 'embeddings': None, 'documents': [['What is a vector database?', 'How do embeddings work?']], 'uris': None, 'data': None, 'metadatas': [[{'source': 'doc1'}, {'source': 'doc2'}]], 'distances': [[0.14219467561685617, 1.306303851125166]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        }
      ],
      "source": [
        "# Query with a new text\n",
        "query_text = \"Explain vector databases.\"\n",
        "query_embedding = model.encode([query_text])\n",
        "\n",
        "# Search in the collection\n",
        "results = collection.query(query_embeddings=query_embedding, n_results=2)\n",
        "print(\"Results:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlGT8rvKXkUI",
        "outputId": "93efdaff-b3e6-4bd4-9c75-dc19aaa25157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results: {'ids': [['3', '1']], 'embeddings': None, 'documents': [['AI and ML applications', 'What is a vector database?']], 'uris': None, 'data': None, 'metadatas': [[{'source': 'doc3'}, {'source': 'doc1'}]], 'distances': [[0.5748007323879616, 1.4356092238719511]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        }
      ],
      "source": [
        "# Query with a new text\n",
        "query_text = \"What is AI/ML?\"\n",
        "query_embedding = model.encode([query_text])\n",
        "\n",
        "# Search in the collection\n",
        "results = collection.query(query_embeddings=query_embedding, n_results=2)\n",
        "print(\"Results:\", results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
